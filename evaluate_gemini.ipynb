{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e1eeacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q -U google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f79357b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google-generativeai)\n",
      "  Downloading google_api_python_client-2.170.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (2.29.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (3.19.6)\n",
      "Requirement already satisfied: pydantic in c:\\users\\msi-gs66 stealth\\.conda\\envs\\ai_builders\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-generativeai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\msi-gs66 stealth\\.conda\\envs\\ai_builders\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
      "Collecting google-api-core (from google-generativeai)\n",
      "  Downloading google_api_core-2.25.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from google-generativeai)\n",
      "  Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google-generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google-generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google-generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\msi-gs66 stealth\\.conda\\envs\\ai_builders\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\msi-gs66 stealth\\.conda\\envs\\ai_builders\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\msi-gs66 stealth\\.conda\\envs\\ai_builders\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.1)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\msi-gs66 stealth\\appdata\\roaming\\python\\python310\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai)\n",
      "  Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl.metadata (4.0 kB)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 0.8/1.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.5 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.0rc1-py3-none-any.whl (160 kB)\n",
      "Downloading protobuf-5.29.4-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading google_api_python_client-2.170.0-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/13.5 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.4/13.5 MB 5.6 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.7/13.5 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 5.0/13.5 MB 5.8 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.0/13.5 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.6/13.5 MB 5.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.3/13.5 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.1/13.5 MB 4.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 9.2/13.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 10.2/13.5 MB 4.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.5 MB 4.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.1/13.5 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.1/13.5 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 4.7 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Downloading grpcio-1.71.0-cp310-cp310-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.8/4.3 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 1.6/4.3 MB 3.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.4/4.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 3.1/4.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 3.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.7 MB/s eta 0:00:00\n",
      "Installing collected packages: uritemplate, protobuf, httplib2, grpcio, proto-plus, googleapis-common-protos, grpcio-status, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google-generativeai\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.19.6\n",
      "    Uninstalling protobuf-3.19.6:\n",
      "      Successfully uninstalled protobuf-3.19.6\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.62.1\n",
      "    Uninstalling grpcio-1.62.1:\n",
      "      Successfully uninstalled grpcio-1.62.1\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc1 google-api-python-client-2.170.0 google-auth-httplib2-0.2.0 google-generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 protobuf-5.29.4 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "mediapipe 0.10.11 requires flatbuffers>=2.0, but you have flatbuffers 1.12 which is incompatible.\n",
      "mediapipe 0.10.11 requires protobuf<4,>=3.11, but you have protobuf 5.29.4 which is incompatible.\n",
      "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 5.29.4 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "648a9e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/120] Score: 2\n",
      "[2/120] Score: 2\n",
      "[3/120] Score: 2\n",
      "[4/120] Score: 2\n",
      "[5/120] Score: 2\n",
      "[6/120] Score: 2\n",
      "[7/120] Score: 2\n",
      "[8/120] Score: 2\n",
      "[9/120] Score: 2\n",
      "[10/120] Score: 2\n",
      "[11/120] Score: 2\n",
      "[12/120] Score: 2\n",
      "[13/120] Score: 2\n",
      "[14/120] Score: 2\n",
      "[15/120] Score: 2\n",
      "[16/120] Score: 2\n",
      "[17/120] Score: 2\n",
      "[18/120] Score: 2\n",
      "[19/120] Score: 2\n",
      "[20/120] Score: 2\n",
      "[21/120] Score: 2\n",
      "[22/120] Score: 2\n",
      "[23/120] Score: 2\n",
      "[24/120] Score: 2\n",
      "[25/120] Score: 2\n",
      "[26/120] Score: 2\n",
      "[27/120] Score: 2\n",
      "[28/120] Score: 2\n",
      "[29/120] Score: 2\n",
      "[30/120] Score: 2\n",
      "[31/120] Score: 2\n",
      "[32/120] Score: 2\n",
      "[33/120] Score: 2\n",
      "[34/120] Score: 2\n",
      "[35/120] Score: 2\n",
      "[36/120] Score: 2\n",
      "[37/120] Score: 2\n",
      "[38/120] Score: 2\n",
      "[39/120] Score: 2\n",
      "[40/120] Score: 2\n",
      "[41/120] Score: 2\n",
      "[42/120] Score: 2\n",
      "[43/120] Score: 2\n",
      "[44/120] Score: 2\n",
      "[45/120] Score: 2\n",
      "[46/120] Score: 2\n",
      "[47/120] Score: 2\n",
      "[48/120] Score: 2\n",
      "[49/120] Score: 2\n",
      "[50/120] Score: 2\n",
      "[51/120] Score: 2\n",
      "[52/120] Score: 2\n",
      "[53/120] Score: 2\n",
      "[54/120] Score: 2\n",
      "[55/120] Score: 2\n",
      "[56/120] Score: 2\n",
      "[57/120] Score: 2\n",
      "[58/120] Score: 2\n",
      "[59/120] Score: 2\n",
      "[60/120] Score: 2\n",
      "[61/120] Score: 2\n",
      "[62/120] Score: 2\n",
      "[63/120] Score: 2\n",
      "[64/120] Score: 2\n",
      "[65/120] Score: 2\n",
      "[66/120] Score: 2\n",
      "[67/120] Score: 2\n",
      "[68/120] Score: 2\n",
      "[69/120] Score: 2\n",
      "[70/120] Score: 2\n",
      "[71/120] Score: 2\n",
      "[72/120] Score: 2\n",
      "[73/120] Score: 2\n",
      "[74/120] Score: 2\n",
      "[75/120] Score: 2\n",
      "[76/120] Score: 2\n",
      "[77/120] Score: 2\n",
      "[78/120] Score: 2\n",
      "[79/120] Score: 2\n",
      "[80/120] Score: 2\n",
      "[81/120] Score: 2\n",
      "[82/120] Score: 2\n",
      "[83/120] Score: 2\n",
      "[84/120] Score: 2\n",
      "[85/120] Score: 2\n",
      "[86/120] Score: 2\n",
      "[87/120] Score: 2\n",
      "[88/120] Score: 2\n",
      "[89/120] Score: 2\n",
      "[90/120] Score: 2\n",
      "[91/120] Score: 2\n",
      "[92/120] Score: 2\n",
      "[93/120] Score: 2\n",
      "[94/120] Score: 2\n",
      "[95/120] Score: 2\n",
      "[96/120] Score: 2\n",
      "[97/120] Score: 2\n",
      "[98/120] Score: 2\n",
      "[99/120] Score: 2\n",
      "[100/120] Score: 2\n",
      "[101/120] Score: 2\n",
      "[102/120] Score: 2\n",
      "[103/120] Score: 2\n",
      "[104/120] Score: 2\n",
      "[105/120] Score: 2\n",
      "[106/120] Score: 2\n",
      "[107/120] Score: 2\n",
      "[108/120] Score: 2\n",
      "[109/120] Score: 2\n",
      "[110/120] Score: 2\n",
      "[111/120] Score: 2\n",
      "[112/120] Score: 2\n",
      "[113/120] Score: 2\n",
      "[114/120] Score: 2\n",
      "[115/120] Score: 2\n",
      "[116/120] Score: 2\n",
      "[117/120] Score: 2\n",
      "[118/120] Score: 2\n",
      "[119/120] Score: 2\n",
      "[120/120] Score: 2\n"
     ]
    }
   ],
   "source": [
    "#completeness\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBVon-UJpRDZTPkMtaXneG2JWLR4ASOLBw\")\n",
    "\n",
    "df = pd.read_csv(\"eval_manual_check_dataset.csv\")\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an expert evaluator. Your task is to judge how completely a model's answer captures the key ideas of an ideal answer to a given question.\n",
    "\n",
    "You will be shown:\n",
    "- The original question\n",
    "- An ideal reference answer\n",
    "- A model-generated answer\n",
    "\n",
    "Your goal is to evaluate how well the model answer includes the core ideas of the ideal answer.\n",
    "\n",
    "Scoring Criteria:\n",
    "- 0 = The model's answer misses the point completely (none of the main ideas are present)\n",
    "- 1 = The model's answer includes some but not all of the main ideas\n",
    "- 2 = The model's answer includes all the main ideas clearly and accurately\n",
    "\n",
    "IMPORTANT: Do not always choose 2. Be precise and critical in judging completeness.\n",
    "\n",
    "Respond in this exact format:\n",
    "Completeness: X\n",
    "\n",
    "Only respond with the score number. Do not add explanations or comments.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Ideal Answer:\n",
    "{ideal_answer}\n",
    "\n",
    "Model Answer:\n",
    "{model_answer}\n",
    "\"\"\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    question = df.loc[i, \"Question\"]\n",
    "    ideal_answer = df.loc[i, \"Ideal Answer\"]\n",
    "    model_answer = df.loc[i, \"Model Answer\"]\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        ideal_answer=ideal_answer,\n",
    "        model_answer=model_answer\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result_text = response.text.strip()\n",
    "        lowered = result_text.lower()\n",
    "\n",
    "        if \"completeness:\" in lowered:\n",
    "            score = lowered.split(\"completeness:\")[1].strip().split()[0]\n",
    "        elif lowered.strip() in {\"0\", \"1\", \"2\"}:\n",
    "            score = lowered.strip()\n",
    "        else:\n",
    "            score = \"\"\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        score = \"\"\n",
    "\n",
    "    completeness_scores.append(score)\n",
    "    print(f\"[{i+1}/{len(df)}] Score: {score}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "df[\"completeness\"] = completeness_scores\n",
    "df.to_csv(\"eval_with_completeness_gemini.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87708d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/120] Score: 2\n",
      "[2/120] Score: 2\n",
      "[3/120] Score: 2\n",
      "[4/120] Score: 2\n",
      "[5/120] Score: 2\n",
      "[6/120] Score: 2\n",
      "[7/120] Score: 2\n",
      "[8/120] Score: 2\n",
      "[9/120] Score: 2\n",
      "[10/120] Score: 2\n",
      "[11/120] Score: 2\n",
      "[12/120] Score: 2\n",
      "[13/120] Score: 2\n",
      "[14/120] Score: 2\n",
      "[15/120] Score: 2\n",
      "[16/120] Score: 2\n",
      "[17/120] Score: 2\n",
      "[18/120] Score: 2\n",
      "[19/120] Score: 2\n",
      "[20/120] Score: 2\n",
      "[21/120] Score: 2\n",
      "[22/120] Score: 2\n",
      "[23/120] Score: 2\n",
      "[24/120] Score: 2\n",
      "[25/120] Score: 2\n",
      "[26/120] Score: 2\n",
      "[27/120] Score: 2\n",
      "[28/120] Score: 2\n",
      "[29/120] Score: 2\n",
      "[30/120] Score: 2\n",
      "[31/120] Score: 2\n",
      "[32/120] Score: 2\n",
      "[33/120] Score: 2\n",
      "[34/120] Score: 2\n",
      "[35/120] Score: 2\n",
      "[36/120] Score: 2\n",
      "[37/120] Score: 2\n",
      "[38/120] Score: 2\n",
      "[39/120] Score: 2\n",
      "[40/120] Score: 2\n",
      "[41/120] Score: 2\n",
      "[42/120] Score: 2\n",
      "[43/120] Score: 2\n",
      "[44/120] Score: 2\n",
      "[45/120] Score: 2\n",
      "[46/120] Score: 2\n",
      "[47/120] Score: 2\n",
      "[48/120] Score: 2\n",
      "[49/120] Score: 2\n",
      "[50/120] Score: 2\n",
      "[51/120] Score: 2\n",
      "[52/120] Score: 2\n",
      "[53/120] Score: 2\n",
      "[54/120] Score: 2\n",
      "[55/120] Score: 2\n",
      "[56/120] Score: 2\n",
      "[57/120] Score: 2\n",
      "[58/120] Score: 2\n",
      "[59/120] Score: 2\n",
      "[60/120] Score: 2\n",
      "[61/120] Score: 2\n",
      "[62/120] Score: 2\n",
      "[63/120] Score: 2\n",
      "[64/120] Score: 2\n",
      "[65/120] Score: 2\n",
      "[66/120] Score: 2\n",
      "[67/120] Score: 2\n",
      "[68/120] Score: 2\n",
      "[69/120] Score: 2\n",
      "[70/120] Score: 2\n",
      "[71/120] Score: 2\n",
      "[72/120] Score: 2\n",
      "[73/120] Score: 2\n",
      "[74/120] Score: 2\n",
      "[75/120] Score: 2\n",
      "[76/120] Score: 2\n",
      "[77/120] Score: 2\n",
      "[78/120] Score: 2\n",
      "[79/120] Score: 2\n",
      "[80/120] Score: 2\n",
      "[81/120] Score: 2\n",
      "[82/120] Score: 2\n",
      "[83/120] Score: 2\n",
      "[84/120] Score: 2\n",
      "[85/120] Score: 2\n",
      "[86/120] Score: 2\n",
      "[87/120] Score: 2\n",
      "[88/120] Score: 2\n",
      "[89/120] Score: 2\n",
      "[90/120] Score: 2\n",
      "[91/120] Score: 2\n",
      "[92/120] Score: 2\n",
      "[93/120] Score: 2\n",
      "[94/120] Score: 2\n",
      "[95/120] Score: 2\n",
      "[96/120] Score: 2\n",
      "[97/120] Score: 2\n",
      "[98/120] Score: 2\n",
      "[99/120] Score: 2\n",
      "[100/120] Score: 2\n",
      "[101/120] Score: 2\n",
      "[102/120] Score: 2\n",
      "[103/120] Score: 2\n",
      "[104/120] Score: 2\n",
      "[105/120] Score: 2\n",
      "[106/120] Score: 2\n",
      "[107/120] Score: 2\n",
      "[108/120] Score: 2\n",
      "[109/120] Score: 2\n",
      "[110/120] Score: 2\n",
      "[111/120] Score: 2\n",
      "[112/120] Score: 2\n",
      "[113/120] Score: 2\n",
      "[114/120] Score: 2\n",
      "[115/120] Score: 2\n",
      "[116/120] Score: 2\n",
      "[117/120] Score: 2\n",
      "[118/120] Score: 2\n",
      "[119/120] Score: 2\n",
      "[120/120] Score: 2\n"
     ]
    }
   ],
   "source": [
    "#rebundancy_ratio\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBVon-UJpRDZTPkMtaXneG2JWLR4ASOLBw\")\n",
    "\n",
    "df = pd.read_csv(\"eval_manual_check_dataset.csv\")\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an expert evaluator. Your task is to judge the Redundancy Ratio of a model-generated answer by comparing it to an ideal reference answer.\n",
    "\n",
    "Your goal is to determine whether the model included more information than what was expected based on the ideal answer.\n",
    "\n",
    "Scoring Criteria:\n",
    "- 0 = The model gives exactly the information expected — no more, no less.\n",
    "- 1 = The model adds a little more than what was expected, but it's acceptable.\n",
    "- 2 = The model adds significantly more information than desired.\n",
    "\n",
    "Respond in this exact format:\n",
    "Redundancy Ratio: X\n",
    "\n",
    "Only respond with the score number. Do not add explanations or comments.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Ideal Answer:\n",
    "{ideal_answer}\n",
    "\n",
    "Model Answer:\n",
    "{model_answer}\n",
    "\"\"\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    question = df.loc[i, \"Question\"]\n",
    "    ideal_answer = df.loc[i, \"Ideal Answer\"]\n",
    "    model_answer = df.loc[i, \"Model Answer\"]\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        ideal_answer=ideal_answer,\n",
    "        model_answer=model_answer\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result_text = response.text.strip()\n",
    "        lowered = result_text.lower()\n",
    "\n",
    "        if \"Redundancy Ratio:\" in lowered:\n",
    "            score = lowered.split(\"Redundancy Ratio:\")[1].strip().split()[0]\n",
    "        elif lowered.strip() in {\"0\", \"1\", \"2\"}:\n",
    "            score = lowered.strip()\n",
    "        else:\n",
    "            score = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        score = \"\"\n",
    "\n",
    "    completeness_scores.append(score)\n",
    "    print(f\"[{i+1}/{len(df)}] Score: {score}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "df[\"rebundancy_ratio\"] = completeness_scores\n",
    "df.to_csv(\"eval_with_rebundancy_ratio_gemini.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d8731f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/120] Score: 2\n",
      "[2/120] Score: 2\n",
      "[3/120] Score: 2\n",
      "[4/120] Score: 2\n",
      "[5/120] Score: 2\n",
      "[6/120] Score: 2\n",
      "[7/120] Score: 2\n",
      "[8/120] Score: 2\n",
      "[9/120] Score: 2\n",
      "[10/120] Score: 2\n",
      "[11/120] Score: 2\n",
      "[12/120] Score: 2\n",
      "[13/120] Score: 2\n",
      "[14/120] Score: 2\n",
      "[15/120] Score: 2\n",
      "[16/120] Score: 2\n",
      "[17/120] Score: 2\n",
      "[18/120] Score: 2\n",
      "[19/120] Score: 2\n",
      "[20/120] Score: 2\n",
      "[21/120] Score: 2\n",
      "[22/120] Score: 2\n",
      "[23/120] Score: 2\n",
      "[24/120] Score: 2\n",
      "[25/120] Score: 2\n",
      "[26/120] Score: 2\n",
      "[27/120] Score: 2\n",
      "[28/120] Score: 2\n",
      "[29/120] Score: 2\n",
      "[30/120] Score: 2\n",
      "[31/120] Score: 2\n",
      "[32/120] Score: 2\n",
      "[33/120] Score: 2\n",
      "[34/120] Score: 2\n",
      "[35/120] Score: 2\n",
      "[36/120] Score: 2\n",
      "[37/120] Score: 2\n",
      "[38/120] Score: 2\n",
      "[39/120] Score: 2\n",
      "[40/120] Score: 2\n",
      "[41/120] Score: 2\n",
      "[42/120] Score: 2\n",
      "[43/120] Score: 2\n",
      "[44/120] Score: 2\n",
      "[45/120] Score: 2\n",
      "[46/120] Score: 2\n",
      "[47/120] Score: 2\n",
      "[48/120] Score: 2\n",
      "[49/120] Score: 2\n",
      "[50/120] Score: 2\n",
      "[51/120] Score: 2\n",
      "[52/120] Score: 2\n",
      "[53/120] Score: 2\n",
      "[54/120] Score: 2\n",
      "[55/120] Score: 2\n",
      "[56/120] Score: 2\n",
      "[57/120] Score: 2\n",
      "[58/120] Score: 2\n",
      "[59/120] Score: 2\n",
      "[60/120] Score: 2\n",
      "[61/120] Score: 2\n",
      "[62/120] Score: 2\n",
      "[63/120] Score: 2\n",
      "[64/120] Score: 2\n",
      "[65/120] Score: 2\n",
      "[66/120] Score: 2\n",
      "[67/120] Score: 2\n",
      "[68/120] Score: 2\n",
      "[69/120] Score: 2\n",
      "[70/120] Score: 2\n",
      "[71/120] Score: 2\n",
      "[72/120] Score: 2\n",
      "[73/120] Score: 2\n",
      "[74/120] Score: 2\n",
      "[75/120] Score: 2\n",
      "[76/120] Score: 2\n",
      "[77/120] Score: 2\n",
      "[78/120] Score: 2\n",
      "[79/120] Score: 2\n",
      "[80/120] Score: 2\n",
      "[81/120] Score: 2\n",
      "[82/120] Score: 2\n",
      "[83/120] Score: 2\n",
      "[84/120] Score: 2\n",
      "[85/120] Score: 2\n",
      "[86/120] Score: 2\n",
      "[87/120] Score: 2\n",
      "[88/120] Score: 2\n",
      "[89/120] Score: 2\n",
      "[90/120] Score: 2\n",
      "[91/120] Score: 2\n",
      "[92/120] Score: 2\n",
      "[93/120] Score: 2\n",
      "[94/120] Score: 2\n",
      "[95/120] Score: 2\n",
      "[96/120] Score: 2\n",
      "[97/120] Score: 2\n",
      "[98/120] Score: 2\n",
      "[99/120] Score: 2\n",
      "[100/120] Score: 2\n",
      "[101/120] Score: 2\n",
      "[102/120] Score: 2\n",
      "[103/120] Score: 2\n",
      "[104/120] Score: 2\n",
      "[105/120] Score: 2\n",
      "[106/120] Score: 2\n",
      "[107/120] Score: 2\n",
      "[108/120] Score: 2\n",
      "[109/120] Score: 2\n",
      "[110/120] Score: 2\n",
      "[111/120] Score: 2\n",
      "[112/120] Score: 2\n",
      "[113/120] Score: 2\n",
      "[114/120] Score: 2\n",
      "[115/120] Score: 2\n",
      "[116/120] Score: 2\n",
      "[117/120] Score: 2\n",
      "[118/120] Score: 2\n",
      "[119/120] Score: 2\n",
      "[120/120] Score: 2\n"
     ]
    }
   ],
   "source": [
    "#rebundancy_severity\n",
    "import google.generativeai as genai\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBVon-UJpRDZTPkMtaXneG2JWLR4ASOLBw\")\n",
    "\n",
    "df = pd.read_csv(\"eval_manual_check_dataset.csv\")\n",
    "\n",
    "model = genai.GenerativeModel(\"models/gemini-1.5-flash-latest\")\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "You are an expert evaluator. Your task is to judge the Redundancy Severity of a model-generated answer by comparing it to an ideal reference answer.\n",
    "\n",
    "Your goal is to evaluate the **impact** of any extra or redundant content in the model's answer. Focus on how distracting, confusing, or misleading it is compared to the expected answer.\n",
    "\n",
    "Scoring Criteria:\n",
    "- 0 = No redundancy. The answer is focused and accurate.\n",
    "- 1 = Minor distraction. There is some unnecessary information, but it does not confuse the meaning.\n",
    "- 2 = Major misunderstanding. The extra content significantly distracts, misleads, or alters the expected meaning.\n",
    "\n",
    "Respond in this exact format:\n",
    "Redundancy Severity: X\n",
    "\n",
    "Only respond with the score number. Do not add explanations or comments.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Ideal Answer:\n",
    "{ideal_answer}\n",
    "\n",
    "Model Answer:\n",
    "{model_answer}\n",
    "\"\"\"\n",
    "\n",
    "completeness_scores = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    question = df.loc[i, \"Question\"]\n",
    "    ideal_answer = df.loc[i, \"Ideal Answer\"]\n",
    "    model_answer = df.loc[i, \"Model Answer\"]\n",
    "\n",
    "    prompt = prompt_template.format(\n",
    "        question=question,\n",
    "        ideal_answer=ideal_answer,\n",
    "        model_answer=model_answer\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        result_text = response.text.strip()\n",
    "        lowered = result_text.lower()\n",
    "\n",
    "        if \"Redundancy Severity:\" in lowered:\n",
    "            score = lowered.split(\"Redundancy Severity:\")[1].strip().split()[0]\n",
    "        elif lowered.strip() in {\"0\", \"1\", \"2\"}:\n",
    "            score = lowered.strip()\n",
    "        else:\n",
    "            score = \"\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at row {i}: {e}\")\n",
    "        score = \"\"\n",
    "\n",
    "    completeness_scores.append(score)\n",
    "    print(f\"[{i+1}/{len(df)}] Score: {score}\")\n",
    "    time.sleep(1)\n",
    "\n",
    "df[\"rebundancy_severity\"] = completeness_scores\n",
    "df.to_csv(\"eval_with_rebundancy_severity_gemini.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_builders",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
